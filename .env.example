# Data4AI Environment Variables
# Copy this file to .env and fill in your values
# 
# üìö Supported Features:
# - AI-Powered Dataset Generation (100+ models via OpenRouter)
# - Multiple Input Formats: Excel (.xlsx), CSV (.csv)
# - Schema Support: Alpaca, Dolly, ShareGPT (chat conversations)
# - DSPy Integration: Dynamic prompt generation with adaptive learning
# - HuggingFace Integration: Direct dataset publishing
# - Natural Language Input: Generate from descriptions
# - Batch Processing: Configurable batch sizes with memory optimization
# - Data Validation: Quality metrics and compliance checking
# - Rate Limiting: Adaptive token bucket with automatic backoff
# - Progress Tracking: Real-time metrics and ETA
# - Error Recovery: Comprehensive error handling with retry logic

# =============================================================================
# üîë REQUIRED: API Configuration
# =============================================================================

# OpenRouter API Key (Required for AI generation)
# Get your key at: https://openrouter.ai/
# Format: sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENROUTER_API_KEY=sk-or-v1-your-key-here

# =============================================================================
# ü§ñ AI Model Configuration
# =============================================================================

# OpenRouter Model (Optional - defaults to meta-llama/llama-3-8b-instruct)
# View available models: data4ai list-models
# Popular models:
# - meta-llama/llama-3-8b-instruct (default, good balance)
# - meta-llama/llama-3-70b-instruct (higher quality, more expensive)
# - anthropic/claude-3-5-sonnet (excellent quality)
# - openai/gpt-4o (best quality, highest cost)
OPENROUTER_MODEL=meta-llama/llama-3-8b-instruct

# =============================================================================
# üîÆ DSPy Configuration (Dynamic Prompt Generation)
# =============================================================================

# Enable DSPy for dynamic prompt generation (default: true)
# Benefits: Context-aware prompts, adaptive learning, schema optimization
# Fallback: Automatic fallback to static prompts if DSPy fails
DATA4AI_USE_DSPY=true

# =============================================================================
# üìä Dataset Schema Configuration
# =============================================================================

# Default dataset schema (default: alpaca)
# Supported schemas:
# - alpaca: instruction/input/output format (recommended for most use cases)
# - dolly: instruction/context/response format (good for Q&A datasets)
# - sharegpt: conversation format (perfect for chat/assistant training)
DATA4AI_DEFAULT_SCHEMA=alpaca

# =============================================================================
# üéõÔ∏è Generation Parameters
# =============================================================================

# Temperature for generation (0.0 to 2.0, default: 0.7)
# - 0.0-0.3: Very focused, consistent outputs
# - 0.4-0.7: Balanced creativity and consistency (recommended)
# - 0.8-1.0: More creative, varied outputs
# - 1.0+: High creativity, less predictable
DATA4AI_TEMPERATURE=0.7

# Maximum rows to generate per dataset (default: 1000)
# Set to 0 for unlimited (not recommended for large datasets)
DATA4AI_MAX_ROWS=1000

# Batch size for API calls (default: 10)
# - Smaller batches (5-10): More reliable, slower
# - Larger batches (20-50): Faster, may hit rate limits
DATA4AI_BATCH_SIZE=10

# Random seed for reproducibility (optional)
# Set to ensure consistent results across runs
# DATA4AI_SEED=42

# =============================================================================
# üìÅ Output Configuration
# =============================================================================

# Default output directory (default: outputs/)
# Generated datasets will be saved to: {output_dir}/{repo_name}/
DATA4AI_OUTPUT_DIR=outputs/

# =============================================================================
# üåê HuggingFace Integration (Optional)
# =============================================================================

# HuggingFace Token for dataset publishing
# Get your token at: https://huggingface.co/settings/tokens
# Required for: data4ai push, --huggingface flag
HF_TOKEN=hf_your-token-here

# HuggingFace Organization (default: your username)
# Datasets will be published to: https://huggingface.co/datasets/{org}/{repo}
HF_ORG=YourOrgName

# =============================================================================
# üìä Analytics and Attribution
# =============================================================================

# Site Attribution (for OpenRouter analytics)
# Used in HTTP-Referer and X-Title headers for API calls
DATA4AI_SITE_URL=https://www.zysec.ai
DATA4AI_SITE_NAME=Data4AI

# =============================================================================
# üìã Schema Examples
# =============================================================================

# Alpaca Schema (Default):
# {
#   "instruction": "What is machine learning?",
#   "input": "Explain in simple terms",
#   "output": "Machine learning is a type of artificial intelligence..."
# }

# Dolly Schema:
# {
#   "instruction": "Summarize this text",
#   "context": "Long text to summarize...",
#   "response": "Summary of the text...",
#   "category": "summarization"
# }

# ShareGPT Schema (Chat Conversations):
# {
#   "conversations": [
#     {"from": "human", "value": "Hello, how are you?"},
#     {"from": "gpt", "value": "I'm doing well, thank you!"}
#   ]
# }

# =============================================================================
# üöÄ Quick Start Examples
# =============================================================================

# 1. Generate from description:
# data4ai prompt --repo my-dataset --description "Create programming questions" --count 100

# 2. Process Excel template:
# data4ai create-sample template.xlsx --dataset alpaca
# data4ai run template.xlsx --repo my-dataset --max-rows 500

# 3. Publish to HuggingFace:
# data4ai prompt --repo public-dataset --description "Educational content" --count 200 --huggingface

# 4. Validate dataset:
# data4ai validate --repo my-dataset

# 5. Get statistics:
# data4ai stats --repo my-dataset

# =============================================================================
# üîß Advanced Configuration
# =============================================================================

# For advanced users: Create ~/.data4ai/config.yaml for persistent settings
# This file will override environment variables and persist across sessions
